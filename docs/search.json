[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduce",
    "section": "",
    "text": "기업 소개\n\n무신사는 국내 최대 온라인 의류 아울렛 플랫폼으로 최근 유명 모델 기용, 대기업과 협업, 오프라인 스토어 런칭 등 공격적 행보를 보이고 있다.\n\n\n\n\n\n기업 정보\n\n\n\n무신사\nMUSINSA\n\n\n\n\n설립연도\n2003년\n\n\n업종\n통신 판매업\n\n\n창업자\n조만호\n\n\n대표자\n한문일\n\n\n연매출\n4,667억 원(2021)\n\n\n영업이익\n542억 원(2021)\n\n\n사원 수\n1,472명(2022)\n\n\n\n\n\n\n\n자회사\n\n\n\n브랜드\n분류\n\n\n\n\n무신사 스탠다드\n자체 PB\n\n\n무신사 스튜디오\n공유오피스\n\n\n무신사 테라스\n복합문화공간\n\n\n무신사 파트너스\n벤처 투자\n\n\n솔드아웃\n거래 중개 플랫폼\n\n\n29CM\n셀렉트샵\n\n\n스타일쉐어\n패션 공유 앱\n\n\n\n\n\n\n\n경쟁사\n\n\n\n브랜드\n분류\n\n\n\n\n브랜디\n의류 플랫폼\n\n\n신세계 W컨셉\n의류 플랫폼\n\n\n카카오 지그재그\n의류 플랫폼\n\n\n머스트잇\n명품 플랫폼\n\n\n발만\n명품 플랫폼\n\n\n트렌비\n명품 플랫폼\n\n\n네이버 크림\n거래 중개 플랫폼\n\n\n\n\n\n\n\n분석 목적\n\n기업 분석을 통해 무신사가 갖는 독보적 BI를 확인하고, 경쟁사와 차별점과 패션 업계 트렌드를 중심으로 나아가야 할 방향과 전략을 제시하고자 함."
  },
  {
    "objectID": "brand.html",
    "href": "brand.html",
    "title": "Brand",
    "section": "",
    "text": "목차\n\n자료 수집\n\n빅카인즈 데이터셋 수집\n\n자료 분석\n\n총빈도 / 무신사\n총빈도 / 패션 플랫폼\n\n상대빈도\n감정 분석\n\n감정 분석 / 무신사\n감정 분석 / 패션 플랫폼\n\n긍정어 부정어 분석\n\n긍정어 부정어 분석 / 무신사\n긍정어 부정어 분석 / 패션 플랫폼\n\n토픽 모델링\n\n토픽 모델링 / 무신사\n토픽 모델링 / 패션 플랫폼\n\n관련 보도 상위 주제어\n\n관련 보도 상위 주제어 / 무신사\n관련 보도 상위 주제어 / 패션 플랫폼\n\n결론\n\n차별점\n전략\n\n\n\n\n1. 자료 수집\n\na. 빅카인즈 데이터셋 수집\n\n\nCode\npkg_v <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n           \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n           \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n           \"stringr\", \"rvest\", \"wordcloud\", \"gt\")\n\n# 패키지 설치 시 사용\n#( pkg_v_installed <- pkg_v %in% installed.packages()[,\"Package\"] )\n\n#( new_pkg <- pkg_v[!pkg_v_installed] )\n\n#if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(pkg_v, require, ch = T)\n\nmusinsa_df <- \nreadxl::read_excel(\"data/NewsResult_20210927-20220927_musinsa.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\nplat_df <- \nreadxl::read_excel(\"data/NewsResult_20210927-20220927_plat.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\n\n\n2021.09.27 - 2022.09.27 무신사 2,056건, 패션 플랫폼 1,330건 확보.\n\n\n\n\n2. 자료 분석\n\na. 총빈도 / 무신사\n\n\nCode\n# \"무신사\"가 \"무신 + 사\"로 반영되어 사전에 \"무신사\" 추가\n#buildDictionary(ext_dic = c('sejong', 'woorimalsam'),\n#                user_dic = data.frame(term=\"무신사\", tag='ncn'),\n#                category_dic_nms=c('brand'))\n\nmusinsa2_df <- \nmusinsa_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_tk <- musinsa2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word, sort = T)\n\nmusinsa_tk <- \nmusinsa_tk %>% \n  filter(!word %in% c(\"무신사\", \"MUSINSA\", \"기자\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"무신사 총빈도\")\n\n\n\n\n\n\n기업과 가장 관련있는 패션, 플랫폼, 온라인이 상위 키워드 위치. 서울 지역 오프라인 샵 개설에 따른 서울, 투자 키워드가 눈에 띄며, 최근 진출한 명품에 대한 기사는 다소 부족함.\n\n\n\nb. 총빈도 / 패션 플랫폼\n\n\nCode\nplat2_df <- \nplat_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"1\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nplat_tk <- plat2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nplat_tk <- \nplat_tk %>% \n  filter(!word %in% c(\"기자\", \"패션\", \"플랫폼\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nplat_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n    labs(title = \"패션 플랫폼 총빈도\")\n\n\n\n\n\n\n무신사보다 신세계, 백화점, 고객, 서비스 등 오프라인 키워드가 두드러짐. 특히 고관여 상품인 명품이 현저히 많이 언급되고 있었음.\n\n\n\n\n3. 상대빈도\n\n\nCode\nvs_df <- rbind(musinsa2_df, plat2_df)\n\nset.seed(5)\n\nvsvs_df <- \n  vs_df[-c(1, 3)] %>% \n  relocate(c(ID, text)) %>%\n  group_by(label) %>% \n  sample_n(size = 1300)\n\nrate_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(posi_odds_ratio = (odds_posi / odds_nega)) %>% \n  filter(rank(posi_odds_ratio) <= 20 | rank(-posi_odds_ratio) <= 20) %>%   arrange(-posi_odds_ratio)\n\nrate_log_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(log_odds_ratio = log(odds_posi / odds_nega)) \n\nweighted_log_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  filter(str_length(word) > 1) %>%\n  filter(word != \"무신사\") %>% \n  filter(word != \"fn\") %>% \n  filter(word != \"기자\") %>% \n  count(word) %>% \n  bind_log_odds(set = label,\n                feature = word,\n                n = n) %>% \n  arrange(-log_odds_weighted)\n\nweighted_log_odds_df %>%\n  group_by(label = ifelse(label > 0, \"패션 플랫폼\", \"무신사\")) %>%\n  slice_max(abs(log_odds_weighted), n = 10) %>%\n  ggplot(aes(x = log_odds_weighted,\n             y = reorder(word, log_odds_weighted),\n             fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\")\n\n\n\n\n\n\n무신사는 자사에 관련된 스탠다드, 유아인, 유니콘 등이 자주 언급되었으며, 패션 플랫폼은 추석, 백화점, 명품 등 오프라인 중심인 모습을 확인할 수 있었음.\n\n\n\n4. 감정 분석\n\na. 감정 분석 / 무신사\n\n\nCode\n# \"knusenti\" 설치 코드\n#url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n\n#dest_v <- \"data/knusenti.zip\"\n\n#download.file(url = url_v, \n#              destfile = dest_v,\n#              mode = \"wb\")\n\n#unzip(\"knusenti.zip\", exdir = \"data\")\n\nsenti_name_v <- list.files(\"data/KnuSentiLex-master/.\")[9]\n\nsenti_dic_df <- read_tsv(str_c(\"data/KnuSentiLex-master/\", senti_name_v), col_names = F)\n\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\n\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\nmusinsa_senti_df <- musinsa2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"무신사 감정빈도 분석\")\n\n\n\n\n\n\n랭킹 시스템을 메인에 배치하고 있기에 인기 상품에 대한 키워드가 가장 많이 나왔으며, 자체 프로모션을 지속적으로 진행하고 있어 할인, 이벤트, 혜택에 대한 언급이 자주 이루어짐. 다만 불편한 UI에 대한 개선과 가품 논란에 따른 부담 키워드도 자주 언급됨.\n\n\n\nb. 감정 분석 / 패션 플랫폼\n\n\nCode\nplat_senti_df <- plat2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nplat_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"패션 플랫폼 감정빈도 분석\",)\n\n\n\n\n\n\n쇼핑에 관련된 만큼 할인, 인기, 혜택 키워드가 상위를 차지하고 있음. 우수, 만족, 고급 등 고가품과 서비스 관련 언급이 자주 이뤄지는게 무신사와 대비됨.\n\n\n\n\n5. 긍정어 부정어 분석\n\na. 긍정어 부정어 분석 / 무신사\n\n\nCode\nmusinsa2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"무신사\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      무신사\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n1559\n    부정\n386\n    중립\n36\n    NA\n114072\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"무신사 긍정어 부정어\")\n\n\n\n\n\n\n4:1 로 긍정어 점수가 높은 편. 프로모션과 관련된 할인, 이벤트, 혜택과 같은 키워드가 긍정어로 분석되었으며, 가품 논란에 따른 부담, 부진, 위축, 가짜 키워드가 부정어로 분석됨.\n\n\n\nb. 긍정어 부정어 분석 / 패션 플랫폼\n\n\nCode\nplat2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"패션 플랫폼\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      패션 플랫폼\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n1177\n    부정\n191\n    중립\n32\n    NA\n74071\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nplat2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nplat2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>% \n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"패션 플랫폼 긍정어 부정어\")\n\n\n\n\n\n\n6:1 로 긍정어 점수가 높은 편. 프로모션에 이어 우수, 만족, 편안, 고급과 같이 서비스와 품질에 대한 키워드가 긍정어로 분석되었으며, 오프라인 시장 축소에 따른 걱정, 위축과 오염, 불량과 같이 제품에 대한 불만 사항이 부정어로 분석됨.\n\n\n\n\n6. 토픽 모델링\n\na. 주제별 단어 확률 분포 / 무신사\n\n\nCode\nmusinsa_topic_tk <- musinsa2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_topic_tk <- \nmusinsa_topic_tk %>% \n  filter(!word %in% c(\"무신사\", \"MUSINSA\", \"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_combined_df <-\n  musinsa_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa2_df, by = \"ID\")\n\nprocessed <- \n  musinsa2_df %>% textProcessor(\n    documents = musinsa_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 3879 of 6037 terms (3879 of 19737 tokens) due to frequency \nRemoving 5 Documents with No Words \nYour corpus now has 2030 documents, 2158 terms and 15858 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_td_beta <- musinsa_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_stm_fit)\n\nmusinsa_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 고객 서비스\",\n                              \"2. 자사 프로모션\",\n                              \"3. 비대면 시장\",\n                              \"4. 기업 투자\",\n                              \"5. 차별화 전략\",\n                              \"6. 사업 다각화\") )\n\nmusinsa_term_topic_name <- \nmusinsa_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_topic_name, by = \"topic\")\n\nmusinsa_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n자사 프로모션과 차별화 전략에서 군집화가 잘 이루어짐.\n\n\n\nb. 주제별 단어 확률 분포 / 패션 플랫폼\n\n\nCode\nplat_topic_tk <- plat2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nplat_topic_tk <- \nplat_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"패션\", \"플랫폼\", \"대상\", \"경제뉴스\",\n                      \"키워드\", \"지난해\", \"투데이\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nplat_combined_df <-\n  plat_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(plat2_df, by = \"ID\")\n\nprocessed <- \n  plat2_df %>% textProcessor(\n    documents = plat_combined_df$text2,\n    metadata = .)\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 2998 of 4600 terms (2998 of 13132 tokens) due to frequency \nYour corpus now has 1313 documents, 1602 terms and 10134 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nplat_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nplat_td_beta <- plat_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(plat_stm_fit)\n\nplat_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 플랫폼 유통\",\n                              \"2. 패션 트렌드\",\n                              \"3. 온라인 경쟁\",\n                              \"4. 오프라인 차별화\",\n                              \"5. 디지털 전략\",\n                              \"6. 기업 프로모션\") )\n\nplat_term_topic_name <- \nplat_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(plat_topic_name, by = \"topic\")\n\nplat_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n패션 트렌드와 디지털 전략에서 군집화가 잘 이루어짐.\n\n\n\n\n7. 관련 보도 상위 주제어\n\na. 관련 보도 상위 주제어 / 무신사\n\n\nCode\nmusinsa_td_gamma <- musinsa_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_top_terms <- \nmusinsa_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_gamma_terms <- \nmusinsa_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"무신사 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n무신사에 입점한 브랜드와 자사몰에서 판매중인 한정판에 대한 기사가 다수임. 펜데믹으로 인한 비대면 시장 활성화에 따라 온라인, 코로나와 같은 기사와 자사 브랜드에 대한 무신사 스탠다드, 스토어에 대한 언급이 잘 이루어지고 있음.\n\n\n\nb. 관련 보도 상위 주제어 / 패션 플랫폼\n\n\nCode\nplat_td_gamma <- plat_stm_fit %>% tidy(matrix = \"gamma\") \n\nplat_top_terms <- \nplat_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nplat_gamma_terms <- \nplat_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(plat_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nplat_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"패션 플랫폼 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n업계의 비대면 시장 진출에 따라 온라인, 거래액과 같은 기사가 다수 있었음. 럭셔리, 디자이너와 같이 사치품 관련 기사와 온라인 프로모션 수단인 메타버스, nft와 같은 기사도 자주 발행되며 기존 패션 플랫폼 이미지를 탈피해 소비자에게 신선한 모습을 보이고자 함을 확인할 수 있었음.\n\n\n\n\n8. 결론\n\na. 차별점\n\n무신사는 다양한 패션 브랜드가 입점해 있는 최대 규모의 온라인 아울렛이라는 점에 차별점이 있음. 또한 시대 트렌드를 재빨리 분석해 판권 취득을 통한 단독 출시와 브랜드 콜라보 작업을 통해 시장을 선점하고 있는 모습이 기존 패션 플랫폼과 차이점임.\n\n\n\nb. 전략\n\n온라인 시장은 선점했지만, 고가품에 대해서는 소비자의 신뢰를 얻지 못하고 있음. 플랫폼의 크기는 유지하되 UI를 개선해 접근성을 높이고, 플래그십 스토어에 투자해 브랜드 고급화 전략을 취하는 것이 바람직해 보임."
  },
  {
    "objectID": "year.html",
    "href": "year.html",
    "title": "Year",
    "section": "",
    "text": "목차\n\n자료 수집\n\n빅카인즈 데이터셋 수집\n\n자료 분석\n\n총빈도 / 21년 무신사\n총빈도 / 22년 무신사\n\n상대빈도\n감정 분석\n\n감정 분석 / 21년 무신사\n감정 분석 / 22년 무신사\n\n긍정어 부정어 분석\n\n긍정어 부정어 분석 / 21년 무신사\n긍정어 부정어 분석 / 22년 무신사\n\n토픽 모델링\n\n토픽 모델링 / 21년 무신사\n토픽 모델링 / 22년 무신사\n\n관련 보도 상위 주제어\n\n관련 보도 상위 주제어 / 21년 무신사\n관련 보도 상위 주제어 / 22년 무신사\n\n결론\n\n차별점\n전략\n\n\n\n\n1. 자료 수집\n\na. 빅카인즈 데이터셋 수집\n\n\nCode\npkg_v <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n           \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n           \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n           \"stringr\", \"rvest\", \"wordcloud\", \"gt\")\n\n# 패키지 설치 시 사용\n#( pkg_v_installed <- pkg_v %in% installed.packages()[,\"Package\"] )\n\n#( new_pkg <- pkg_v[!pkg_v_installed] )\n\n#if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(pkg_v, require, ch = T)\n\nmusinsa_21year_df <- \nreadxl::read_excel(\"data/NewsResult_20210101-20211004_musinsa.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\nmusinsa_22year_df <- \nreadxl::read_excel(\"data/NewsResult_20220101-20221004_musinsa.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\n\n\n2021.01.01 - 2021.10.04 간 1,413건, 2022.01.01 - 2022.10.04 간 1,597건 확보.\n\n\n\n\n2. 자료 분석\n\na. 총빈도 / 무신사 21년\n\n\nCode\n# \"무신사\"가 \"무신 + 사\"로 반영되어 사전에 \"무신사\" 추가\n#buildDictionary(ext_dic = c('sejong', 'woorimalsam'),\n#                user_dic = data.frame(term=\"역직구\", tag='ncn'),\n#                category_dic_nms=c('brand'))\n\nmusinsa_21year2_df <- \nmusinsa_21year_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_21year_tk <- musinsa_21year2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word, sort = T)\n\nmusinsa_21year_tk <- \nmusinsa_21year_tk %>% \n  filter(!word %in% c(\"무신사\", \"MUSINSA\", \"기자\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_21year_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"21년 무신사 총빈도\")\n\n\n\n\n\n\n기업과 관련된 패션, 브랜드, 온라인 키워드가 자주 언급되었으며, 투자, 카드, 시장과 같이 사업적 측면이 두드러짐. 성차별과 제스처에 관련된 사건이 논란 키워드를 통해 부정적으로 언급됨.\n\n\n\nb. 총빈도 / 무신사 22년\n\n\nCode\nmusinsa_22year2_df <- \nmusinsa_22year_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"1\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_22year_tk <- musinsa_22year2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nmusinsa_22year_tk <- \nmusinsa_22year_tk %>% \n  filter(!word %in% c(\"무신사\", \"MUSINSA\", \"기자\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_22year_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n    labs(title = \"22년 무신사 총빈도\")\n\n\n\n\n\n\n21년도와 동일하게 기업과 관련된 패션, 브랜드, 플랫폼과 같은 키워드가 잘 언급되고 있었으며, 오프라인 샵 개설에 따른 서울, 국내와 고가품 플랫폼 런칭으로 명품이 새로 언급되기 시작함.\n\n\n\n\n3. 상대빈도\n\n\nCode\nvs_df <- rbind(musinsa_21year2_df, musinsa_22year2_df)\n\nset.seed(15)\n\nvsvs_df <- \n  vs_df[-c(1, 3)] %>% \n  relocate(c(ID, text)) %>%\n  group_by(label) %>% \n  sample_n(size = 1400)\n\nrate_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(posi_odds_ratio = (odds_posi / odds_nega)) %>% \n  filter(rank(posi_odds_ratio) <= 20 | rank(-posi_odds_ratio) <= 20) %>%   arrange(-posi_odds_ratio)\n\nrate_log_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(log_odds_ratio = log(odds_posi / odds_nega)) \n\nweighted_log_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  filter(str_length(word) > 1) %>%\n  filter(word != \"무신사\") %>% \n  filter(word != \"fn\") %>% \n  filter(word != \"기자\") %>% \n  filter(word != \"파이낸셜\") %>% \n  filter(word != \"[헤럴드경제=이정아\") %>% \n  count(word) %>% \n  bind_log_odds(set = label,\n                feature = word,\n                n = n) %>% \n  arrange(-log_odds_weighted)\n\nweighted_log_odds_df %>%\n  group_by(label = ifelse(label > 0, \"22년 무신사\", \"21년 무신사\")) %>%\n  slice_max(abs(log_odds_weighted), n = 10) %>%\n  ggplot(aes(x = log_odds_weighted,\n             y = reorder(word, log_odds_weighted),\n             fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\")\n\n\n\n\n\n\n21년에는 콜라보와 관련된 참이슬, GS25와 논란에 따른 손가락, 포스터, 실망이 상대적으로 자주 언급되었으며, 22년에는 주식 무상 증여에 따른 증여, 무상과 짝퉁 논란에 대한 가품, 피어 키워드가 자주 언급되었음.\n\n\n\n4. 감정 분석\n\na. 감정 분석 / 21년 무신사\n\n\nCode\n# \"knusenti\" 설치 코드\n#url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n\n#dest_v <- \"data/knusenti.zip\"\n\n#download.file(url = url_v, \n#              destfile = dest_v,\n#              mode = \"wb\")\n\n#unzip(\"knusenti.zip\", exdir = \"data\")\n\nsenti_name_v <- list.files(\"data/KnuSentiLex-master/.\")[9]\n\nsenti_dic_df <- read_tsv(str_c(\"data/KnuSentiLex-master/\", senti_name_v), col_names = F)\n\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\n\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\nmusinsa_21year_senti_df <- musinsa_21year2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_21year_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"21년 무신사 감정빈도 분석\")\n\n\n\n\n\n\n프로모션에 대한 할인, 인기, 이벤트, 혜택과 같은 키워드가 긍정어로 자주 언급됨. 부정어로는 성차별과 제스처 논란으로 혐오, 실망이 자주 언급된 것을 확인할 수 있었음.\n\n\n\nb. 감정 분석 / 22년 무신사\n\n\nCode\nmusinsa_22year_senti_df <- musinsa_22year2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_22year_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"22년 무신사 감정빈도 분석\")\n\n\n\n\n\n\n21년과 동일하게 프로모션에 대한 인기, 할인 키워드가 긍정어로 수집되었으며, 부정어로 가품 논란에 따른 부담, 개선 키워드가 자주 언급되는 모습을 보임.\n\n\n\n\n5. 긍정어 부정어 분석\n\na. 긍정어 부정어 분석 / 21년 무신사\n\n\nCode\nmusinsa_21year2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"21년 무신사\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      21년 무신사\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n1265\n    부정\n281\n    중립\n47\n    NA\n77908\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa_21year2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa_21year2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"21년 무신사 긍정어 부정어\")\n\n\n\n\n\n\n4.5:1 로 긍정어 점수가 높은 편. 프로모션과 관련된 할인, 인기, 이벤트와 같은 키워드가 긍정어로 분석되었으며, 성차별과 제스처 논란에 따른 혐오, 실망, 비난 키워드가 부정어로 분석됨.\n\n\n\nb. 긍정어 부정어 분석 / 22년 무신사\n\n\nCode\nmusinsa_22year2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"22년 무신사\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      22년 무신사\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n1171\n    부정\n277\n    중립\n24\n    NA\n88168\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa_22year2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa_22year2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"22년 무신사 긍정어 부정어\")\n\n\n\n\n\n\n4.2:1 로 21년 보다 긍정어 점수 비율이 낮아짐. 전년과 동일하게 인기, 할인 키워드가 긍정어 상위를 차지했으며, 가품 논란에 따른 부담, 위축, 가짜가 부정어로 자주 언급되는 모습을 보임.\n\n\n\n\n6. 토픽 모델링\n\na. 주제별 단어 확률 분포 / 21년 무신사\n\n\nCode\nmusinsa_21year_topic_tk <- musinsa_21year2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_21year_topic_tk <- \nmusinsa_21year_topic_tk %>% \n  filter(!word %in% c(\"무신사\", \"MUSINSA\", \"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_21year_combined_df <-\n  musinsa_21year_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa_21year2_df, by = \"ID\")\n\nprocessed <- \n  musinsa_21year2_df %>% textProcessor(\n    documents = musinsa_21year_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 2921 of 4511 terms (2921 of 13983 tokens) due to frequency \nRemoving 2 Documents with No Words \nYour corpus now has 1397 documents, 1590 terms and 11062 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_21year_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_21year_td_beta <- musinsa_21year_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_stm_fit)\n\nmusinsa_21year_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 자사 마케팅\",\n                              \"2. 기업 경영\",\n                              \"3. 비대면 시장\",\n                              \"4. 시장 동향\",\n                              \"5. 패션 카테고리\",\n                              \"6. 경쟁 기업\") )\n\nmusinsa_21year_term_topic_name <- \nmusinsa_21year_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_21year_topic_name, by = \"topic\")\n\nmusinsa_21year_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n자사 마케팅과 시장 동향에서 군집화가 잘 이루어짐.\n\n\n\nb. 주제별 단어 확률 분포 / 22년 무신사\n\n\nCode\nmusinsa_22year_topic_tk <- musinsa_22year2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_22year_topic_tk <- \nmusinsa_22year_topic_tk %>% \n  filter(!word %in% c(\"무신사\", \"MUSINSA\", \"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\", \"헤럴드경제이정아\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_22year_combined_df <-\n  musinsa_22year_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa_22year2_df, by = \"ID\")\n\nprocessed <- \n  musinsa_22year2_df %>% textProcessor(\n    documents = musinsa_22year_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 3155 of 4866 terms (3155 of 15160 tokens) due to frequency \nRemoving 5 Documents with No Words \nYour corpus now has 1571 documents, 1711 terms and 12005 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_22year_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_22year_td_beta <- musinsa_22year_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_stm_fit)\n\nmusinsa_22year_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 비대면 온라인\",\n                              \"2. 자사 라인업\",\n                              \"3. 럭셔리 리셀\",\n                              \"4. 자사 프로모션\",\n                              \"5. 플랫폼 경쟁\",\n                              \"6. 경쟁 기업\") )\n\nmusinsa_22year_term_topic_name <- \nmusinsa_22year_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_22year_topic_name, by = \"topic\")\n\nmusinsa_22year_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n자사 라인업과 경쟁 기업에서 군집화가 잘 이루어짐.\n\n\n\n\n7. 관련 보도 상위 주제어\n\na. 관련 보도 상위 주제어 / 21년 무신사\n\n\nCode\nmusinsa_21year_td_gamma <- musinsa_21year_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_21year_top_terms <- \nmusinsa_21year_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_21year_gamma_terms <- \nmusinsa_21year_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_21year_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_21year_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"21년 무신사 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n무신사에서 판매중인 브랜드와 디자인, 컬렉션과 같이 의류 관련 기사가 자주 보도됨. 스타트, 유니콘 키워드로 기업 성장을 주목하고 있으며, 카카오, 신세계, 지그재그와 비교해 매출 증대를 조명하는 내용이 자주 언급되고 있음.\n\n\n\nb. 관련 보도 상위 주제어 / 22년 무신사\n\n\nCode\nmusinsa_22year_td_gamma <- musinsa_22year_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_22year_top_terms <- \nmusinsa_22year_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_22year_gamma_terms <- \nmusinsa_22year_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_22year_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_22year_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"22년 무신사 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n21년 보다 펜데믹으로 인한 플랫폼, 온라인과 같은 비대면 서비스가 상대적으로 자주 언급됨. 공격적인 프로모션을 진행함에 따라 스토어, 스탠다드, 유아인 등 무신사의 자사 브랜드 관련 키워드가 잘 언급되고 있음.\n\n\n\n\n8. 결론\n\na. 차이점\n\n21년에는 타 기업과 콜라보에 관련된 기사가 많았음. 또한 성차별 논란이 크게 언급되며 기업 이미지 차원에서 위기를 맞이함. 22년에는 펜데믹으로 인한 비대면 시장 활성화, 자사 브랜드 런칭에 관한 기사가 주를 이룸. 다만 가품 논란으로 브랜드 신뢰도에 타격을 입은 모습을 확인할 수 있음.\n\n\n\nb. 전략\n\n대체적으로 무신사의 프로모션 소식, 브랜드 런칭 등 자사에 긍정적인 방향으로 기사가 전개되고 있었음. 그러나 이슈가 발생하면 파급력이 굉장히 커지고, 기업 이미지에 심각한 타격을 입는 모습을 보였기 때문에 기업 PR 차원에서 전략적인 관리가 필요할 것으로 보임."
  },
  {
    "objectID": "future.html",
    "href": "future.html",
    "title": "Future",
    "section": "",
    "text": "목차\n\n자료 수집\n\n빅카인즈 데이터셋 수집\n\n자료 분석\n\n총빈도 / 21년 패션 트렌드\n총빈도 / 22년 패션 트렌드\n\n상대빈도\n감정 분석\n\n감정 분석 / 21년 패션 트렌드\n감정 분석 / 22년 패션 트렌드\n\n긍정어 부정어 분석\n\n긍정어 부정어 분석 / 21년 패션 트렌드\n긍정어 부정어 분석 / 22년 패션 트렌드\n\n토픽 모델링\n\n토픽 모델링 / 21년 패션 트렌드\n토픽 모델링 / 22년 패션 트렌드\n\n관련 보도 상위 주제어\n\n관련 보도 상위 주제어 / 21년 패션 트렌드\n관련 보도 상위 주제어 / 22년 패션 트렌드\n\n결론\n\n차별점\n전략\n\n\n\n\n1. 자료 수집\n\na. 빅카인즈 데이터셋 수집\n\n\nCode\npkg_v <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n           \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n           \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n           \"stringr\", \"rvest\", \"wordcloud\", \"gt\")\n\n# 패키지 설치 시 사용\n#( pkg_v_installed <- pkg_v %in% installed.packages()[,\"Package\"] )\n\n#( new_pkg <- pkg_v[!pkg_v_installed] )\n\n#if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(pkg_v, require, ch = T)\n\nmusinsa_21future_df <- \nreadxl::read_excel(\"data/NewsResult_20210101-20211012_future.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\nmusinsa_22future_df <- \nreadxl::read_excel(\"data/NewsResult_20220101-20221012_future.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\n\n\n2021.01.01 - 2021.10.12 간 1,122건, 2022.01.01 - 2022.10.12 간 1,148건 확보.\n\n\n\n\n2. 자료 분석\n\na. 총빈도 / 패션 트렌드 21년\n\n\nCode\n# \"무신사\"가 \"무신 + 사\"로 반영되어 사전에 \"무신사\" 추가\n#buildDictionary(ext_dic = c('sejong', 'woorimalsam'),\n#                user_dic = data.frame(term=\"역직구\", tag='ncn'),\n#                category_dic_nms=c('brand'))\n\nmusinsa_21future2_df <- \nmusinsa_21future_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_21future_tk <- musinsa_21future2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word, sort = T)\n\nmusinsa_21future_tk <- \nmusinsa_21future_tk %>% \n  filter(!word %in% c(\"기자\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_21future_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"21년 패션 트렌드 총빈도\")\n\n\n\n\n\n\n21년에는 백화점, 신세계, 롯데백화점과 같이 오프라인 스토어와 더불어 새로운 고객 연령대에 진입한 MZ 세대에 대한 관심이 고객, 소비 키워드로 나타났음.\n\n\n\nb. 총빈도 / 패션 트렌드 22년\n\n\nCode\nmusinsa_22future2_df <- \nmusinsa_22future_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"1\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_22future_tk <- musinsa_22future2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nmusinsa_22future_tk <- \nmusinsa_22future_tk %>% \n  filter(!word %in% c(\"기자\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_22future_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n    labs(title = \"22년 패션 트렌드 총빈도\")\n\n\n\n\n\n\n22년에는 새로 경쟁 부문으로 올라온 고가품에 대해 업계, 명품 키워드가 떠올랐으며 온라인 아울렛이던 무신사의 오프라인 매장 진출로 서울, 매장이 자주 언급됨.\n\n\n\n\n3. 상대빈도\n\n\nCode\nvs_df <- rbind(musinsa_21future2_df, musinsa_22future2_df)\n\nset.seed(5)\n\nvsvs_df <- \n  vs_df[-c(1, 3)] %>% \n  relocate(c(ID, text)) %>%\n  group_by(label) %>% \n  sample_n(size = 1100)\n\nrate_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(posi_odds_ratio = (odds_posi / odds_nega)) %>% \n  filter(rank(posi_odds_ratio) <= 20 | rank(-posi_odds_ratio) <= 20) %>%   arrange(-posi_odds_ratio)\n\nrate_log_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(log_odds_ratio = log(odds_posi / odds_nega)) \n\nweighted_log_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  filter(str_length(word) > 1) %>%\n  filter(word != \"기자\") %>%\n  filter(word != \"[헤럴드경제=이정아\") %>%\n  count(word) %>% \n  bind_log_odds(set = label,\n                feature = word,\n                n = n) %>% \n  arrange(-log_odds_weighted)\n\nweighted_log_odds_df %>%\n  group_by(label = ifelse(label > 0, \"22년 패션 트렌드\", \"21년 패션 트렌드\")) %>%\n  slice_max(abs(log_odds_weighted), n = 10) %>%\n  ggplot(aes(x = log_odds_weighted,\n             y = reorder(word, log_odds_weighted),\n             fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\")\n\n\n\n\n\n\n21년에는 리사이클 패션에 관련된 에어백과 내셔널지오그래픽의 패션 브랜드화가 주목받은 반면, 22년에는 코로나 종식에 대한 패션 산업 부흥의 기대로 엔데믹과 디지털 마케팅 기법으로 사용되기 시작한 NFT에 대한 언급이 상대적으로 많았음.\n\n\n\n4. 감정 분석\n\na. 감정 분석 / 21년 패션 트렌드\n\n\nCode\n# \"knusenti\" 설치 코드\n#url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n\n#dest_v <- \"data/knusenti.zip\"\n\n#download.file(url = url_v, \n#              destfile = dest_v,\n#              mode = \"wb\")\n\n#unzip(\"knusenti.zip\", exdir = \"data\")\n\nsenti_name_v <- list.files(\"data/KnuSentiLex-master/.\")[9]\n\nsenti_dic_df <- read_tsv(str_c(\"data/KnuSentiLex-master/\", senti_name_v), col_names = F)\n\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\n\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\nmusinsa_21future_senti_df <- musinsa_21future2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_21future_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"21년 패션 트렌드 감정빈도 분석\")\n\n\n\n\n\n\n21년은 MZ 세대의 패션 트렌드가 개성, 혁신, 적극, 열광 키워드로 자주 언급됨. 다만 코로나로 인한 바이러스, 불황과 같이 패션 산업의 불확실한 전망에 대한 언급 역시 자주 이루어짐.\n\n\n\nb. 감정 분석 / 22년 패션 트렌드\n\n\nCode\nmusinsa_22future_senti_df <- musinsa_22future2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_22future_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"22년 패션 트렌드 감정빈도 분석\")\n\n\n\n\n\n\n22년은 가치, 고급, 성공과 같은 키워드로 명품에 대한 언급이 많아졌으며 엔데믹으로 인한 기대, 상승세가 기사 전반에서 긍정적 전망을 예고하고 있었음.\n\n\n\n\n5. 긍정어 부정어 분석\n\na. 긍정어 부정어 분석 / 21년 패션 트렌드\n\n\nCode\nmusinsa_21future2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"21년 패션 트렌드\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      21년 패션 트렌드\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n1279\n    부정\n187\n    중립\n18\n    NA\n62653\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa_21future2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa_21future2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"21년 패션 트렌드 긍정어 부정어\")\n\n\n\n\n\n\n6.8:1 로 긍정어 점수가 높은 편. MZ 세대의 선호 스타일에 대해 개성, 혁신과 같은 키워드가 긍정어로 분석되었으며, 전방위적인 코로나 확산에 따른 바이러스, 불황, 위축 키워드가 부정어로 분석됨.\n\n\n\nb. 긍정어 부정어 분석 / 22년 패션 트렌드\n\n\nCode\nmusinsa_22future2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"22년 패션 트렌드\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      22년 패션 트렌드\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n1215\n    부정\n174\n    중립\n12\n    NA\n64254\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa_22future2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa_22future2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"22년 패션 트렌드 긍정어 부정어\")\n\n\n\n\n\n\n6.9:1 로 긍정어 점수가 높은 편. 전년보다 명품에 대한 언급이 증가해 가치, 고급, 성공 키워드가 긍정어 상위를 차지했으며, 명품 취급 브랜드에서 발생한 가품 논란에 따른 부담, 위축, 걱정이 부정어로 언급됨.\n\n\n\n\n6. 토픽 모델링\n\na. 주제별 단어 확률 분포 / 21년 패션 트렌드\n\n\nCode\nmusinsa_21future_topic_tk <- musinsa_21future2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_21future_topic_tk <- \nmusinsa_21future_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_21future_combined_df <-\n  musinsa_21future_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa_21future2_df, by = \"ID\")\n\nprocessed <- \n  musinsa_21future2_df %>% textProcessor(\n    documents = musinsa_21future_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 2569 of 3938 terms (2569 of 11481 tokens) due to frequency \nYour corpus now has 1119 documents, 1369 terms and 8912 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_21future_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_21future_td_beta <- musinsa_21future_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_21future_stm_fit)\n\nmusinsa_21future_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 롯데 브랜드\",\n                              \"2. 트렌드 변화\",\n                              \"3. 비대면 시장\",\n                              \"4. 코로나 리스크\",\n                              \"5. 디지털 마케팅\",\n                              \"6. 패션 업계\") )\n\nmusinsa_21future_term_topic_name <- \nmusinsa_21future_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_21future_topic_name, by = \"topic\")\n\nmusinsa_21future_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n비대면 시장과 디지털 마케팅에서 군집화가 잘 이루어짐.\n\n\n\nb. 주제별 단어 확률 분포 / 22년 패션 트렌드\n\n\nCode\nmusinsa_22future_topic_tk <- musinsa_22future2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_22future_topic_tk <- \nmusinsa_22future_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\", \"헤럴드경제이정아\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_22future_combined_df <-\n  musinsa_22future_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa_22future2_df, by = \"ID\")\n\nprocessed <- \n  musinsa_22future2_df %>% textProcessor(\n    documents = musinsa_22future_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 2539 of 3924 terms (2539 of 11748 tokens) due to frequency \nYour corpus now has 1139 documents, 1385 terms and 9209 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_22future_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_22future_td_beta <- musinsa_22future_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_22future_stm_fit)\n\nmusinsa_22future_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 명품 트렌드\",\n                              \"2. 시장 다각화\",\n                              \"3. 패션 플랫폼\",\n                              \"4. 플랫폼 산업\",\n                              \"5. 마케팅 전략\",\n                              \"6. 온라인 마케팅\") )\n\nmusinsa_22future_term_topic_name <- \nmusinsa_22future_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_22future_topic_name, by = \"topic\")\n\nmusinsa_22future_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n명품 트렌드와 패션 플랫폼에서 군집화가 잘 이루어짐.\n\n\n\n\n7. 관련 보도 상위 주제어\n\na. 관련 보도 상위 주제어 / 21년 패션 트렌드\n\n\nCode\nmusinsa_21future_td_gamma <- musinsa_21future_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_21future_top_terms <- \nmusinsa_21future_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_21future_gamma_terms <- \nmusinsa_21future_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_21future_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_21future_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"21년 패션 트렌드 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n펜데믹으로 인한 백화점, 유통업계의 사업 활로에 대한 언급이 자주 이루어짐. 업계는 패션 트렌드 흐름에 집중하고 있으며 여기서 골프웨어, 아웃도어, 친환경이 자주 다뤄진 것을 확인할 수 있었음.\n\n\n\nb. 관련 보도 상위 주제어 / 22년 패션 트렌드\n\n\nCode\nmusinsa_22future_td_gamma <- musinsa_22future_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_22future_top_terms <- \nmusinsa_22future_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_22future_gamma_terms <- \nmusinsa_22future_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_22future_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_22future_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"22년 패션 트렌드 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n21년 보다 온라인 시장인 무신사, 서비스, 플랫폼과 같은 비대면 서비스에 집중하는 모습을 보임. 다만 프리미엄 키워드가 롯데백화점, 롯데와 같이 언급되며 명품에 대해 여전히 대기업과 오프라인 시장이 우위인 것을 확인할 수 있었음.\n\n\n\n\n8. 결론\n\na. 차이점\n\n21년에는 MZ 세대의 니즈에 따른 개성, 혁신과 같이 니치 브랜드의 유행 모습과 코로나 확산으로 비대면 시장에 대한 관심을 확인할 수 있었음. 22년에는 명품에 대한 관심이 높아지며 고급, 가치와 같은 요소가 중요하게 여겨졌음. 다만 엔데믹의 접근과 가품 논란에 여러 온라인 브랜드가 관련되면서 오히려 오프라인 브랜드의 입지가 높아짐.\n\n\n\nb. 전략\n\n개성을 추구하는 니치 브랜드 역시 여전히 활발하게 활동하고 있지만, 코로나로 부터 일상 회복이 이루어지면서 억제되던 소비 심리가 다시금 커지고 있어 명품이 새로운 트렌드로 자리잡고 있음. 따라서 프리미엄 브랜드 이미지를 구축해 가품 논란에 대한 소비자 신뢰를 회복하고 오프라인 마켓에 대응 능력을 갖추는 것이 필요해보임. 또한 마케팅 수단에 메타버스, NFT와 같이 다양한 디지털 요소가 새롭게 활용되고 있기에 이를 적극 활용하는 편이 바람직해 보임."
  },
  {
    "objectID": "risk.html",
    "href": "risk.html",
    "title": "Risk",
    "section": "",
    "text": "목차\n\n자료 수집\n\n빅카인즈 데이터셋 수집\n\n자료 분석\n\n총빈도 / 21년 무신사 위기\n총빈도 / 22년 무신사 위기\n\n상대빈도\n감정 분석\n\n감정 분석 / 21년 무신사 위기\n감정 분석 / 22년 무신사 위기\n\n긍정어 부정어 분석\n\n긍정어 부정어 분석 / 21년 무신사 위기\n긍정어 부정어 분석 / 22년 무신사 위기\n\n토픽 모델링\n\n토픽 모델링 / 21년 무신사 위기\n토픽 모델링 / 22년 무신사 위기\n\n관련 보도 상위 주제어\n\n관련 보도 상위 주제어 / 21년 무신사 위기\n관련 보도 상위 주제어 / 22년 무신사 위기\n\n결론\n\n차별점\n전략\n\n\n\n\n1. 자료 수집\n\na. 빅카인즈 데이터셋 수집\n\n\nCode\npkg_v <- c(\"tidyverse\", \"tidytext\", \"readxl\", \"kableExtra\", \n           \"multilinguer\", \"RcppMeCab\", \"KoNLP\", \"lubridate\", \n           \"tidylo\", \"stm\", \"reshape2\", \"dplyr\", \"ggplot2\", \n           \"stringr\", \"rvest\", \"wordcloud\", \"gt\")\n\n# 패키지 설치 시 사용\n#( pkg_v_installed <- pkg_v %in% installed.packages()[,\"Package\"] )\n\n#( new_pkg <- pkg_v[!pkg_v_installed] )\n\n#if(length(new_pkg)) install.packages(new_pkg)\n\nlapply(pkg_v, require, ch = T)\n\nmusinsa_21risk_df <- \nreadxl::read_excel(\"data/NewsResult_20210101-20211030_risk.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\nmusinsa_22risk_df <- \nreadxl::read_excel(\"data/NewsResult_20220101-20221030_risk.xlsx\") %>% \n  select(일자, 제목, 본문, cat = `통합 분류1`) \n\n\n\n2021.01.01 - 2021.10.30 간 816건, 2022.01.01 - 2022.10.30 간 745건 확보.\n\n\n\n\n2. 자료 분석\n\na. 총빈도 / 무신사 위기 21년\n\n\nCode\n# \"무신사\"가 \"무신 + 사\"로 반영되어 사전에 \"무신사\" 추가\n#buildDictionary(ext_dic = c('sejong', 'woorimalsam'),\n#                user_dic = data.frame(term=\"역직구\", tag='ncn'),\n#                category_dic_nms=c('brand'))\n\nmusinsa_21risk2_df <- \nmusinsa_21risk_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"0\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_21risk_tk <- musinsa_21risk2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word, sort = T)\n\nmusinsa_21risk_tk <- \nmusinsa_21risk_tk %>% \n  filter(!word %in% c(\"기자\")) %>% \n  filter(!word %in% c(\"무신사\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_21risk_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"21년 무신사 위기 총빈도\")\n\n\n\n\n\n\n21년도에는 여성 고객에만 쿠폰을 지급해 논란이 된 성차별 사건과 손가락 혐오 제스처 논란이 논란, 남성, 온라인으로 다수 언급되었음.\n\n\n\nb. 총빈도 / 무신사 위기 22년\n\n\nCode\nmusinsa_22risk2_df <- \nmusinsa_22risk_df %>% \n  distinct(제목, .keep_all = T) %>% \n  mutate(ID = factor(row_number())) %>% \n  mutate(label = \"1\") %>%\n  unite(제목, 본문, col = \"text\", sep = \" \") %>% \n  mutate(text = str_squish(text))\n\nmusinsa_22risk_tk <- musinsa_22risk2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F) %>%\n  count(word, sort = T)\n\nmusinsa_22risk_tk <- \nmusinsa_22risk_tk %>% \n  filter(!word %in% c(\"기자\")) %>% \n  filter(!word %in% c(\"무신사\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_22risk_tk %>%\n  filter(str_length(word) > 1) %>%\n  slice_max(n, n = 15) %>% \n  mutate(word = reorder(word, n)) %>% \n  ggplot(aes(word, n)) +\n  geom_col() +\n  coord_flip() +\n    labs(title = \"22년 무신사 위기 총빈도\")\n\n\n\n\n\n\n22년도에는 명품에 대한 가품 논란이 명품, 논란, 가품, 짝퉁 키워드로 자주 언급되고 있었음. 경쟁사와 공방을 벌이면서 크림, 업계도 동시에 언급되는 모습을 보임.\n\n\n\n\n3. 상대빈도\n\n\nCode\nvs_df <- rbind(musinsa_21risk2_df, musinsa_22risk2_df)\n\nset.seed(5)\n\nvsvs_df <- \n  vs_df[-c(1, 3)] %>% \n  relocate(c(ID, text)) %>%\n  group_by(label) %>% \n  sample_n(size = 730)\n\nrate_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(posi_odds_ratio = (odds_posi / odds_nega)) %>% \n  filter(rank(posi_odds_ratio) <= 20 | rank(-posi_odds_ratio) <= 20) %>%   arrange(-posi_odds_ratio)\n\nrate_log_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  count(word) %>% \n  pivot_wider(names_from = label,\n              values_from = n, \n              values_fill = list(n = 0)) %>% \n  rename(posi = `1`, nega = `0`) %>% \n  mutate(odds_posi = ((posi+1)/sum(posi+1)),\n         odds_nega = ((nega+1)/sum(nega+1))) %>% \n  mutate(log_odds_ratio = log(odds_posi / odds_nega)) \n\nweighted_log_odds_df <- \nvsvs_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n#  separate(word, c(\"word\", \"pos\"), sep = \"/\") %>% \n#  filter(pos == \"nng\") %>% \n  filter(str_length(word) > 1) %>%\n  filter(word != \"기자\") %>%\n  filter(word != \"무신사\") %>%\n  count(word) %>% \n  bind_log_odds(set = label,\n                feature = word,\n                n = n) %>% \n  arrange(-log_odds_weighted)\n\nweighted_log_odds_df %>%\n  group_by(label = ifelse(label > 0, \"22년 무신사 위기\", \"21년 무신사 위기\")) %>%\n  slice_max(abs(log_odds_weighted), n = 10) %>%\n  ggplot(aes(x = log_odds_weighted,\n             y = reorder(word, log_odds_weighted),\n             fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\")\n\n\n\n\n\n\n21년도에는 혐오 제스처 논란에 관련된 손가락, 포스터, 성차별 키워드가 자주 언급된 반면에, 22년도에는 네이버 크림과 다투게 된 가품 논란으로 판정, 명품, 크림, 가품에 대한 언급이 상대적으로 많았음.\n\n\n\n4. 감정 분석\n\na. 감정 분석 / 21년 무신사 위기\n\n\nCode\n# \"knusenti\" 설치 코드\n#url_v <- \"https://github.com/park1200656/KnuSentiLex/archive/refs/heads/master.zip\"\n\n#dest_v <- \"data/knusenti.zip\"\n\n#download.file(url = url_v, \n#              destfile = dest_v,\n#              mode = \"wb\")\n\n#unzip(\"knusenti.zip\", exdir = \"data\")\n\nsenti_name_v <- list.files(\"data/KnuSentiLex-master/.\")[9]\n\nsenti_dic_df <- read_tsv(str_c(\"data/KnuSentiLex-master/\", senti_name_v), col_names = F)\n\nsenti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)\n\nknu_dic_df <- senti_dic_df %>% \n  filter(!is.na(sScore))\n\nmusinsa_21risk_senti_df <- musinsa_21risk2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_21risk_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"21년 무신사 위기 감정빈도 분석\")\n\n\n\n\n\n\n21년도는 여러 브랜드에서 전방위적으로 논란이 된 혐오 제스처에 대해 모양, 혐오, 의혹 키워드가 부정어 상위를 차지하고 있었음. 자사에 관련된 긍정어 할인, 이벤트, 가치가 언급된 기사는 부정어에 비해 많지 않았음.\n\n\n\nb. 감정 분석 / 22년 무신사 위기\n\n\nCode\nmusinsa_22risk_senti_df <- musinsa_22risk2_df %>% \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  count(word, sScore, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  mutate(word = reorder(word, n)) %>% \n  slice_head(n = 20)\n\nmusinsa_22risk_senti_df %>% \n  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +\n    labs(title = \"22년 무신사 위기 감정빈도 분석\")\n\n\n\n\n\n\n22년도는 혐오 논란이 이어진 반면에, 가품 논란이 있었음에도 불구하고 크게 언급되지는 않았으며 오히려 보상과 개선책 시행으로 프로모션에 대한 긍정어가 다수 있었음. 논란에 관련된 키워드로는 의혹, 의심, 가짜가 부정어로 자리하고 있음.\n\n\n\n\n5. 긍정어 부정어 분석\n\na. 긍정어 부정어 분석 / 21년 무신사 위기\n\n\nCode\nmusinsa_21risk2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"21년 무신사 위기\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      21년 무신사 위기\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n628\n    부정\n425\n    중립\n49\n    NA\n45552\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa_21risk2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa_21risk2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"21년 무신사 위기 긍정어 부정어\")\n\n\n\n\n\n\n1.5:1 로 긍정어 점수가 높은 편. 혐오 제스처 논란에 대해 혐오, 실망, 망신과 같은 키워드가 부정어로 분석되었으며, 긍정어로는 자사 프로모션과 관련된 할인, 이벤트, 세일 키워드가 언급되었음.\n\n\n\nb. 긍정어 부정어 분석 / 22년 무신사 위기\n\n\nCode\nmusinsa_22risk2_df %>% \n  unnest_tokens(word, text) %>% \n  left_join(knu_dic_df) %>% \n  mutate(sScore = ifelse(sScore >= 1, \"긍정\",\n                         ifelse(sScore <= -1, \"부정\", \"중립\"))) %>% \n  count(sScore) %>%\n  gt() %>%\n  tab_header(title = \"22년 무신사 위기\",\n             subtitle = \"긍정어 부정어 점수\")\n\n\n\n\n\n\n  \n    \n      22년 무신사 위기\n    \n    \n      긍정어 부정어 점수\n    \n  \n  \n    \n      sScore\n      n\n    \n  \n  \n    긍정\n488\n    부정\n347\n    중립\n27\n    NA\n41951\n  \n  \n  \n\n\n\n\nCode\n# 워드클라우드\nmusinsa_22risk2_df %>% \n  unnest_tokens(word, text) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>% \n  filter(emotion != \"중립\") %>% \n  count(word, emotion, sort = T) %>% \n  filter(str_length(word) > 1) %>% \n  filter(!word %in% c(\"대상\")) %>% \n  reshape2::acast(word ~ emotion, value.var = \"n\", fill = 0) %>% \n  comparison.cloud(colors = c(\"blue\", \"red\"), max.words = 50)\n\n\n\n\n\nCode\nmusinsa_22risk2_df %>%   \n  unnest_tokens(word, text, token = extractNoun) %>% \n  inner_join(knu_dic_df) %>% \n  mutate(emotion = ifelse(sScore > 0, \"긍정\", ifelse(sScore < 0, \"부정\", \"중립\"))) %>%\n  mutate(label = ifelse(sScore > 0, \"1\", ifelse(sScore < 0, \"0\", \"2\"))) %>%\n  filter(label != \"중립\") %>%\n  count(word, emotion, label, sort = T) %>%\n  filter(str_length(word) > 1) %>%\n  filter(!word %in% c(\"대상\")) %>% \n  group_by(label = ifelse(label > 0, \"긍정\", \"부정\")) %>%\n  slice_head(n = 15) %>%\n  ggplot(aes(x = n,\n             y = reorder(word, n), fill = label)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~label, scale = \"free\") +\n  labs(title = \"22년 무신사 위기 긍정어 부정어\")\n\n\n\n\n\n\n1.4:1 로 전년도에 비해 부정어 언급이 많은 편. 가품 논란에 따른 의혹, 의심, 가짜 키워드가 부정어 상위를 차지했으며, 다만 개선책에 대한 기사 또한 자주 언급되며 적극, 인정, 신뢰 키워드가 긍정어로 분석됨.\n\n\n\n\n6. 토픽 모델링\n\na. 주제별 단어 확률 분포 / 21년 무신사 위기\n\n\nCode\nmusinsa_21risk_topic_tk <- musinsa_21risk2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_21risk_topic_tk <- \nmusinsa_21risk_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_21risk_combined_df <-\n  musinsa_21risk_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa_21risk2_df, by = \"ID\")\n\nprocessed <- \n  musinsa_21risk2_df %>% textProcessor(\n    documents = musinsa_21risk_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 2299 of 3339 terms (2299 of 7670 tokens) due to frequency \nRemoving 4 Documents with No Words \nYour corpus now has 807 documents, 1040 terms and 5371 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_21risk_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_21risk_td_beta <- musinsa_21risk_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_21risk_stm_fit)\n\nmusinsa_21risk_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 제스처 논란\",\n                              \"2. 플랫폼 업계\",\n                              \"3. 코로나 이슈\",\n                              \"4. 브랜드 프로모션\",\n                              \"5. 경쟁 브랜드\",\n                              \"6. 비대면 시장\") )\n\nmusinsa_21risk_term_topic_name <- \nmusinsa_21risk_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_21risk_topic_name, by = \"topic\")\n\nmusinsa_21risk_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n제스처 논란과 경쟁 브랜드에서 군집화가 잘 이루어짐.\n\n\n\nb. 주제별 단어 확률 분포 / 22년 무신사 위기\n\n\nCode\nmusinsa_22risk_topic_tk <- musinsa_22risk2_df %>% \n  mutate(text = str_remove_all(text, \"[^(\\\\w+|\\\\s)]\")) %>%  \n  unnest_tokens(word, text, token = extractNoun, drop = F)\n\nmusinsa_22risk_topic_tk <- \nmusinsa_22risk_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"대상\",\n                      \"투데이\", \"글로벌\", \"지난달\", \"지난해\",\n                      \"가운데\", \"헤럴드경제이정아\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))\n\nmusinsa_22risk_combined_df <-\n  musinsa_22risk_topic_tk %>%\n  group_by(ID) %>%\n  summarise(text2 = str_flatten(word, \" \")) %>%\n  ungroup() %>% \n  inner_join(musinsa_22risk2_df, by = \"ID\")\n\nprocessed <- \n  musinsa_22risk2_df %>% textProcessor(\n    documents = musinsa_22risk_combined_df$text2,\n    metadata = .,\n    )\n\n\nBuilding corpus... \nConverting to Lower Case... \nRemoving punctuation... \nRemoving stopwords... \nRemoving numbers... \nStemming... \nCreating Output... \n\n\nCode\nout <-\n  prepDocuments(processed$documents,\n                processed$vocab,\n                processed$meta, \n                lower.thresh = 1)\n\n\nRemoving 2238 of 3091 terms (2238 of 6852 tokens) due to frequency \nRemoving 6 Documents with No Words \nYour corpus now has 729 documents, 853 terms and 4614 tokens.\n\n\nCode\ndocs <- out$documents\nvocab <- out$vocab\nmeta <- out$meta\n\ntopicN <- c(3, 10)\n\n#storage <- searchK(out$documents, out$vocab, K = topicN)\n\nmusinsa_22risk_stm_fit <-\n  stm(\n    documents = docs,\n    vocab = vocab,\n    K = 6,\n    data = meta,\n    init.type = \"Spectral\",\n    seed = 25,\n    verbose = F\n  )\n\nmusinsa_22risk_td_beta <- musinsa_22risk_stm_fit %>% tidy(matrix = 'beta') \n\n#labelTopics(musinsa_22risk_stm_fit)\n\nmusinsa_22risk_topic_name <- tibble(topic = 1:6,\n                     name = c(\"1. 리셀 사업\",\n                              \"2. 오프라인 스토어\",\n                              \"3. 디지털 마케팅\",\n                              \"4. PPL 프로모션\",\n                              \"5. 정부 논란\",\n                              \"6. 글로벌 패션\") )\n\nmusinsa_22risk_term_topic_name <- \nmusinsa_22risk_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 7) %>% \n  left_join(musinsa_22risk_topic_name, by = \"topic\")\n\nmusinsa_22risk_term_topic_name %>% \n  ggplot(aes(x = beta, \n             y = reorder_within(term, beta, name),\n             fill = name)) +\n  geom_col(show.legend = F) +\n  facet_wrap(~name, scales = \"free\") +\n  scale_y_reordered() +\n  labs(x = expression(\"단어 확률분포: \"~beta), y = NULL,\n       title = \"주제별 단어 확률 분포\",\n       subtitle = \"주제별로 다른 단어들로 군집\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n디지털 마케팅과 PPL 프로모션에서 군집화가 잘 이루어짐.\n\n\n\n\n7. 관련 보도 상위 주제어\n\na. 관련 보도 상위 주제어 / 21년 무신사 위기\n\n\nCode\nmusinsa_21risk_td_gamma <- musinsa_21risk_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_21risk_top_terms <- \nmusinsa_21risk_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_21risk_gamma_terms <- \nmusinsa_21risk_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_21risk_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_21risk_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"21년 무신사 위기 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n무신사의 제스처 논란에 대해 무신사, 온라인, 이미지 키워드로 언급이 자주 이루어짐. 마찬가지로 다양한 업계에서 동일한 논란이 일었기에 손가락, 포스터, 커뮤니티 키워드로 문제에 대한 기사가 자주 발행되었음.\n\n\n\nb. 관련 보도 상위 주제어 / 22년 무신사 위기\n\n\nCode\nmusinsa_22risk_td_gamma <- musinsa_22risk_stm_fit %>% tidy(matrix = \"gamma\") \n\nmusinsa_22risk_top_terms <- \nmusinsa_22risk_td_beta %>% \n  group_by(topic) %>% \n  slice_max(beta, n = 5) %>% \n  select(topic, term) %>% \n  summarise(terms = str_flatten(term, collapse = \", \")) \n\nmusinsa_22risk_gamma_terms <- \nmusinsa_22risk_td_gamma %>% \n  group_by(topic) %>% \n  summarise(gamma = mean(gamma)) %>% \n  left_join(musinsa_22risk_top_terms, by = 'topic') %>% \n  mutate(topic = str_c(\"주제\", topic),\n         topic = reorder(topic, gamma))\n\nmusinsa_22risk_gamma_terms %>% \n  ggplot(aes(x = gamma, y = topic, fill = topic)) +\n  geom_col(show.legend = F) +\n  geom_text(aes(label = round(gamma, 2)),\n            hjust = 1.4) +\n  geom_text(aes(label = terms), \n            hjust = -0.05) +\n  scale_x_continuous(expand = c(0, 0),\n                     limit = c(0, 1)) +\n  labs(x = expression(\"문서 확률분포\"~(gamma)), y = NULL,\n       title = \"22년 무신사 위기 관련 보도 상위 주제어\",\n       subtitle = \"주제별로 기여도가 높은 단어 중심\") +\n  theme(plot.title = element_text(size = 20))\n\n\n\n\n\n\n무신사와 네이버 크림 간 짝퉁 공방이 무신사, 티셔츠, 네이버, 에센셜 키워드로 가장 많이 언급됨. 펜데믹으로 인한 오프라인 업계의 위기와 사업 다각화가 신세계, 백화점, 코로나 키워드로 군집화되어 다뤄지고 있었음.\n\n\n\n\n8. 결론\n\na. 차이점\n\n21년도에는 성차별과 제스처 논란이 가장 큰 위기였으며 특히 손가락 제스처의 경우 업계에서 전반적으로 발생해 해당 사건을 다룬 기사마다 무신사가 부정적으로 언급되고 있었음. 22년도의 경우 네이버 크림과 다투게 된 짝퉁 공방에 대해 부정적 언급이 자주 이루어졌지만, 무신사의 전적인 보상과 향후 재발 방지에 대한 대책이 비교적 자주 기사화되며 긍정적 방향으로 전환되는 모습을 보임.\n\n\n\nb. 전략\n\n시대의 트렌드 흐름에 재빨리 적응해야 하는 패션 업계의 특성 상 민감한 이슈에 대해 충분히 검토하지 않고 자사 프로모션에 적용하는 섣부른 모습을 보임. 가품 논란 또한 보상책은 존재했지만 미연에 사태를 방지할 수 있는 검수 시스템이 미흡했음. 앞으로는 논란이 발생하지 않도록 전반적인 분야에 대해 사전 검수를 철저히 하고 이슈 발생 시 적극적으로 대처하는 전략이 필요할 것으로 보임."
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Report",
    "section": "",
    "text": "test test…"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "report.html#getting-up",
    "href": "report.html#getting-up",
    "title": "Report",
    "section": "Getting up",
    "text": "Getting up\n\nTurn off alarm\nGet out of bed"
  },
  {
    "objectID": "report.html#going-to-sleep",
    "href": "report.html#going-to-sleep",
    "title": "Report",
    "section": "Going to sleep",
    "text": "Going to sleep\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "report.html#목차",
    "href": "report.html#목차",
    "title": "Report",
    "section": "목차",
    "text": "목차\n\n\n\n기업 소개\n분석 목적\n데이터셋 수집\n데이터 분석\n결론"
  },
  {
    "objectID": "report.html#기업-소개",
    "href": "report.html#기업-소개",
    "title": "Report",
    "section": "기업 소개",
    "text": "기업 소개\n\n\n\n\n\n\n국내 최대 의류 아울렛 플랫폼\n21년 기준 연매출 4,667억 원, 영업이익 542억 원\n10번 째 유니콘 기업 선정"
  },
  {
    "objectID": "report.html#분석-목적",
    "href": "report.html#분석-목적",
    "title": "Report",
    "section": "분석 목적",
    "text": "분석 목적\n\n\n\n기업 분석을 통해 무신사가 갖는 독보적 BI를 확인하고, 경쟁사와 차별점과 패션 업계 트렌드를 중심으로 나아가야 할 방향과 전략을 제시하고자 함.\n\n\n\n\n\nflowchart LR\n  A(자료 수집) --> B(자료 분석)\n  B --> C{결과 도출}\n  C --> D(전략 제안)\n  C --> E(위기 관리)"
  },
  {
    "objectID": "report.html#데이터셋-수집-방법",
    "href": "report.html#데이터셋-수집-방법",
    "title": "Report",
    "section": "데이터셋 수집 방법",
    "text": "데이터셋 수집 방법\n\n\n한국언론진흥재단 빅카인즈 기사 수집\n\n\n\n패션 브랜드 간 비교\n\n2021.09.27 - 2022.09.27 무신사 2,056건, 패션 플랫폼 1,330건 확보.\n무신사, 패션 브랜드 키워드 검색.\n\n\n\n\n\n연간 비교\n\n2021.01.01 - 2021.10.04 간 1,413건, 2022.01.01 - 2022.10.04 간 1,597건 확보.\n무신사 키워드 검색."
  },
  {
    "objectID": "report.html#분석-결과",
    "href": "report.html#분석-결과",
    "title": "Report",
    "section": "분석 결과",
    "text": "분석 결과\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "report.html#결론",
    "href": "report.html#결론",
    "title": "Report",
    "section": "결론",
    "text": "결론\n\nGet in bed\nCount sheep\n\n\n\nHome"
  },
  {
    "objectID": "report.html#주요-코드-수정-내용",
    "href": "report.html#주요-코드-수정-내용",
    "title": "Report",
    "section": "주요 코드 수정 내용",
    "text": "주요 코드 수정 내용\n\n\n\n브랜드 명 “무신사”가 “무신 + 사”로 반영돼 사전에 “무신사” 추가.\n\nbuildDictionary(ext_dic = c('sejong', 'woorimalsam'),\n                user_dic = data.frame(term=\"무신사\", tag='ncn'),\n                category_dic_nms=c('brand'))\n\n\n\n무의미하게 반복되는 단어 제거.\n\nmusinsa_topic_tk <- \nmusinsa_topic_tk %>% \n  filter(!word %in% c(\"기자\", \"투데이\", \"가운데\", \"경제뉴스\")) %>% \n  filter(str_detect(word, \"[:alpha:]+\"))"
  },
  {
    "objectID": "report.html#데이터셋-수집-방법-1",
    "href": "report.html#데이터셋-수집-방법-1",
    "title": "Report",
    "section": "데이터셋 수집 방법",
    "text": "데이터셋 수집 방법\n\n\n한국언론진흥재단 빅카인즈 기사 수집\n\n\n\n트렌드 분석\n\n2021.01.01 - 2021.10.12 간 1,122건, 2022.01.01 - 2022.10.12 간 1,148건 확보.\n패션 트렌드 키워드 검색.\n\n\n\n\n\n위기 분석\n\n2021.01.01 - 2021.10.30 간 816건, 2022.01.01 - 2022.10.30 간 745건 확보.\n무신사, 패션 브랜드, 위기, 논란 키워드 검색"
  },
  {
    "objectID": "report.html#기업-소개-1",
    "href": "report.html#기업-소개-1",
    "title": "Report",
    "section": "기업 소개",
    "text": "기업 소개\n\n\n\n\n\n\n국내 최대 의류 아울렛 플랫폼\n21년 기준 연매출 4,667억 원, 영업이익 542억 원\n10번 째 유니콘 기업 선정"
  },
  {
    "objectID": "report.html#분석-목적-1",
    "href": "report.html#분석-목적-1",
    "title": "Report",
    "section": "분석 목적",
    "text": "분석 목적\n\n\n\n기업 분석을 통해 무신사가 갖는 독보적 BI를 확인하고, 경쟁사와 차별점과 패션 업계 트렌드를 중심으로 나아가야 할 방향과 전략을 제시하고자 함.\n\n\n\n\n\nflowchart LR\n  A(자료 수집) --> B(자료 분석)\n  B --> C{결과 도출}\n  C --> D(전략 제안)\n  C --> E(위기 관리)"
  },
  {
    "objectID": "report.html#데이터셋-수집-방법-2",
    "href": "report.html#데이터셋-수집-방법-2",
    "title": "Report",
    "section": "데이터셋 수집 방법",
    "text": "데이터셋 수집 방법\n\n\n한국언론진흥재단 빅카인즈 기사 수집\n\n\n\n트렌드 분석\n\n2021.01.01 - 2021.10.12 간 1,122건, 2022.01.01 - 2022.10.12 간 1,148건 확보.\n패션 트렌드 키워드 검색.\n\n\n\n\n\n위기 분석\n\n2021.01.01 - 2021.10.30 간 816건, 2022.01.01 - 2022.10.30 간 745건 확보.\n무신사, 패션 브랜드, 위기, 논란 키워드 검색"
  },
  {
    "objectID": "report.html#데이터-분석-1",
    "href": "report.html#데이터-분석-1",
    "title": "Report",
    "section": "데이터 분석",
    "text": "데이터 분석\n\ntesttest"
  },
  {
    "objectID": "report.html#한국언론진흥재단-빅카인즈-기사-수집",
    "href": "report.html#한국언론진흥재단-빅카인즈-기사-수집",
    "title": "Report",
    "section": "한국언론진흥재단 빅카인즈 기사 수집",
    "text": "한국언론진흥재단 빅카인즈 기사 수집\n\n\n\n패션 브랜드 간 비교\n\n2021.09.27 - 2022.09.27 무신사 2,056건, 패션 플랫폼 1,330건 확보.\n무신사, 패션 브랜드 키워드 검색.\n\n\n\n\n\n연간 비교\n\n2021.01.01 - 2021.10.04 간 1,413건, 2022.01.01 - 2022.10.04 간 1,597건 확보.\n무신사 키워드 검색."
  },
  {
    "objectID": "report.html#분석-결과-1",
    "href": "report.html#분석-결과-1",
    "title": "Report",
    "section": "분석 결과",
    "text": "분석 결과\n\nGet in bed\nCount sheep"
  },
  {
    "objectID": "report.html#결론-1",
    "href": "report.html#결론-1",
    "title": "Report",
    "section": "결론",
    "text": "결론\n\nGet in bed\nCount sheep\n\n\n\nHome"
  },
  {
    "objectID": "report.html#한국언론진흥재단-빅카인즈-수집",
    "href": "report.html#한국언론진흥재단-빅카인즈-수집",
    "title": "Report",
    "section": "한국언론진흥재단 빅카인즈 수집",
    "text": "한국언론진흥재단 빅카인즈 수집\n\n\n\n패션 브랜드 간 비교\n\n무신사, 패션 브랜드 키워드 검색.\n2021.09.27 - 2022.09.27 무신사 2,056건, 패션 플랫폼 1,330건 확보.\n\n\n\n\n\n연간 비교\n\n무신사 키워드 검색.\n2021.01.01 - 2021.10.04 간 1,413건, 2022.01.01 - 2022.10.04 간 1,597건 확보."
  },
  {
    "objectID": "report.html#한국언론진흥재단-빅카인즈-수집-1",
    "href": "report.html#한국언론진흥재단-빅카인즈-수집-1",
    "title": "Report",
    "section": "한국언론진흥재단 빅카인즈 수집",
    "text": "한국언론진흥재단 빅카인즈 수집\n\n\n\n트렌드 분석\n\n패션 트렌드 키워드 검색.\n2021.01.01 - 2021.10.12 간 1,122건, 2022.01.01 - 2022.10.12 간 1,148건 확보.\n\n\n\n\n\n위기 분석\n\n무신사, 패션 브랜드, 위기, 논란 키워드 검색\n2021.01.01 - 2021.10.30 간 816건, 2022.01.01 - 2022.10.30 간 745건 확보."
  },
  {
    "objectID": "report.html#한국언론진흥재단-빅카인즈",
    "href": "report.html#한국언론진흥재단-빅카인즈",
    "title": "Report",
    "section": "한국언론진흥재단 빅카인즈",
    "text": "한국언론진흥재단 빅카인즈\n\n\n\n패션 브랜드 간 비교\n\n무신사, 패션 브랜드 키워드 검색.\n2021.09.27 - 2022.09.27 무신사 2,056건, 패션 플랫폼 1,330건 확보.\n\n\n\n\n\n연간 비교\n\n무신사 키워드 검색.\n2021.01.01 - 2021.10.04 간 1,413건, 2022.01.01 - 2022.10.04 간 1,597건 확보."
  },
  {
    "objectID": "report.html#한국언론진흥재단-빅카인즈-1",
    "href": "report.html#한국언론진흥재단-빅카인즈-1",
    "title": "Report",
    "section": "한국언론진흥재단 빅카인즈",
    "text": "한국언론진흥재단 빅카인즈\n\n\n\n트렌드 분석\n\n패션 트렌드 키워드 검색.\n2021.01.01 - 2021.10.12 간 1,122건, 2022.01.01 - 2022.10.12 간 1,148건 확보.\n\n\n\n\n\n위기 분석\n\n무신사, 패션 브랜드, 위기, 논란 키워드 검색\n2021.01.01 - 2021.10.30 간 816건, 2022.01.01 - 2022.10.30 간 745건 확보."
  }
]